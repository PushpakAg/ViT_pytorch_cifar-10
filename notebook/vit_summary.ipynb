{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook.ViT import ViT\n",
    "import torch\n",
    "import torchsummary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([10, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "            Linear-2             [-1, 196, 768]         590,592\n",
      "      PatchEncoder-3             [-1, 197, 768]               0\n",
      "         LayerNorm-4             [-1, 197, 768]           1,536\n",
      "            Linear-5             [-1, 197, 768]         590,592\n",
      "            Linear-6             [-1, 197, 768]         590,592\n",
      "            Linear-7             [-1, 197, 768]         590,592\n",
      "           Dropout-8          [-1, 12, 197, 64]               0\n",
      "            Linear-9             [-1, 197, 768]         590,592\n",
      "          Dropout-10             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-11             [-1, 197, 768]               0\n",
      "        LayerNorm-12             [-1, 197, 768]           1,536\n",
      "           Linear-13            [-1, 197, 3072]       2,362,368\n",
      "             GELU-14            [-1, 197, 3072]               0\n",
      "          Dropout-15            [-1, 197, 3072]               0\n",
      "           Linear-16             [-1, 197, 768]       2,360,064\n",
      "          Dropout-17             [-1, 197, 768]               0\n",
      "              MLP-18             [-1, 197, 768]               0\n",
      "TransformerEncoder-19             [-1, 197, 768]               0\n",
      "        LayerNorm-20             [-1, 197, 768]           1,536\n",
      "           Linear-21             [-1, 197, 768]         590,592\n",
      "           Linear-22             [-1, 197, 768]         590,592\n",
      "           Linear-23             [-1, 197, 768]         590,592\n",
      "          Dropout-24          [-1, 12, 197, 64]               0\n",
      "           Linear-25             [-1, 197, 768]         590,592\n",
      "          Dropout-26             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-27             [-1, 197, 768]               0\n",
      "        LayerNorm-28             [-1, 197, 768]           1,536\n",
      "           Linear-29            [-1, 197, 3072]       2,362,368\n",
      "             GELU-30            [-1, 197, 3072]               0\n",
      "          Dropout-31            [-1, 197, 3072]               0\n",
      "           Linear-32             [-1, 197, 768]       2,360,064\n",
      "          Dropout-33             [-1, 197, 768]               0\n",
      "              MLP-34             [-1, 197, 768]               0\n",
      "TransformerEncoder-35             [-1, 197, 768]               0\n",
      "        LayerNorm-36             [-1, 197, 768]           1,536\n",
      "           Linear-37             [-1, 197, 768]         590,592\n",
      "           Linear-38             [-1, 197, 768]         590,592\n",
      "           Linear-39             [-1, 197, 768]         590,592\n",
      "          Dropout-40          [-1, 12, 197, 64]               0\n",
      "           Linear-41             [-1, 197, 768]         590,592\n",
      "          Dropout-42             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-43             [-1, 197, 768]               0\n",
      "        LayerNorm-44             [-1, 197, 768]           1,536\n",
      "           Linear-45            [-1, 197, 3072]       2,362,368\n",
      "             GELU-46            [-1, 197, 3072]               0\n",
      "          Dropout-47            [-1, 197, 3072]               0\n",
      "           Linear-48             [-1, 197, 768]       2,360,064\n",
      "          Dropout-49             [-1, 197, 768]               0\n",
      "              MLP-50             [-1, 197, 768]               0\n",
      "TransformerEncoder-51             [-1, 197, 768]               0\n",
      "        LayerNorm-52             [-1, 197, 768]           1,536\n",
      "           Linear-53             [-1, 197, 768]         590,592\n",
      "           Linear-54             [-1, 197, 768]         590,592\n",
      "           Linear-55             [-1, 197, 768]         590,592\n",
      "          Dropout-56          [-1, 12, 197, 64]               0\n",
      "           Linear-57             [-1, 197, 768]         590,592\n",
      "          Dropout-58             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-59             [-1, 197, 768]               0\n",
      "        LayerNorm-60             [-1, 197, 768]           1,536\n",
      "           Linear-61            [-1, 197, 3072]       2,362,368\n",
      "             GELU-62            [-1, 197, 3072]               0\n",
      "          Dropout-63            [-1, 197, 3072]               0\n",
      "           Linear-64             [-1, 197, 768]       2,360,064\n",
      "          Dropout-65             [-1, 197, 768]               0\n",
      "              MLP-66             [-1, 197, 768]               0\n",
      "TransformerEncoder-67             [-1, 197, 768]               0\n",
      "        LayerNorm-68             [-1, 197, 768]           1,536\n",
      "           Linear-69             [-1, 197, 768]         590,592\n",
      "           Linear-70             [-1, 197, 768]         590,592\n",
      "           Linear-71             [-1, 197, 768]         590,592\n",
      "          Dropout-72          [-1, 12, 197, 64]               0\n",
      "           Linear-73             [-1, 197, 768]         590,592\n",
      "          Dropout-74             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-75             [-1, 197, 768]               0\n",
      "        LayerNorm-76             [-1, 197, 768]           1,536\n",
      "           Linear-77            [-1, 197, 3072]       2,362,368\n",
      "             GELU-78            [-1, 197, 3072]               0\n",
      "          Dropout-79            [-1, 197, 3072]               0\n",
      "           Linear-80             [-1, 197, 768]       2,360,064\n",
      "          Dropout-81             [-1, 197, 768]               0\n",
      "              MLP-82             [-1, 197, 768]               0\n",
      "TransformerEncoder-83             [-1, 197, 768]               0\n",
      "        LayerNorm-84             [-1, 197, 768]           1,536\n",
      "           Linear-85             [-1, 197, 768]         590,592\n",
      "           Linear-86             [-1, 197, 768]         590,592\n",
      "           Linear-87             [-1, 197, 768]         590,592\n",
      "          Dropout-88          [-1, 12, 197, 64]               0\n",
      "           Linear-89             [-1, 197, 768]         590,592\n",
      "          Dropout-90             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-91             [-1, 197, 768]               0\n",
      "        LayerNorm-92             [-1, 197, 768]           1,536\n",
      "           Linear-93            [-1, 197, 3072]       2,362,368\n",
      "             GELU-94            [-1, 197, 3072]               0\n",
      "          Dropout-95            [-1, 197, 3072]               0\n",
      "           Linear-96             [-1, 197, 768]       2,360,064\n",
      "          Dropout-97             [-1, 197, 768]               0\n",
      "              MLP-98             [-1, 197, 768]               0\n",
      "TransformerEncoder-99             [-1, 197, 768]               0\n",
      "       LayerNorm-100             [-1, 197, 768]           1,536\n",
      "          Linear-101             [-1, 197, 768]         590,592\n",
      "          Linear-102             [-1, 197, 768]         590,592\n",
      "          Linear-103             [-1, 197, 768]         590,592\n",
      "         Dropout-104          [-1, 12, 197, 64]               0\n",
      "          Linear-105             [-1, 197, 768]         590,592\n",
      "         Dropout-106             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-107             [-1, 197, 768]               0\n",
      "       LayerNorm-108             [-1, 197, 768]           1,536\n",
      "          Linear-109            [-1, 197, 3072]       2,362,368\n",
      "            GELU-110            [-1, 197, 3072]               0\n",
      "         Dropout-111            [-1, 197, 3072]               0\n",
      "          Linear-112             [-1, 197, 768]       2,360,064\n",
      "         Dropout-113             [-1, 197, 768]               0\n",
      "             MLP-114             [-1, 197, 768]               0\n",
      "TransformerEncoder-115             [-1, 197, 768]               0\n",
      "       LayerNorm-116             [-1, 197, 768]           1,536\n",
      "          Linear-117             [-1, 197, 768]         590,592\n",
      "          Linear-118             [-1, 197, 768]         590,592\n",
      "          Linear-119             [-1, 197, 768]         590,592\n",
      "         Dropout-120          [-1, 12, 197, 64]               0\n",
      "          Linear-121             [-1, 197, 768]         590,592\n",
      "         Dropout-122             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-123             [-1, 197, 768]               0\n",
      "       LayerNorm-124             [-1, 197, 768]           1,536\n",
      "          Linear-125            [-1, 197, 3072]       2,362,368\n",
      "            GELU-126            [-1, 197, 3072]               0\n",
      "         Dropout-127            [-1, 197, 3072]               0\n",
      "          Linear-128             [-1, 197, 768]       2,360,064\n",
      "         Dropout-129             [-1, 197, 768]               0\n",
      "             MLP-130             [-1, 197, 768]               0\n",
      "TransformerEncoder-131             [-1, 197, 768]               0\n",
      "       LayerNorm-132             [-1, 197, 768]           1,536\n",
      "          Linear-133             [-1, 197, 768]         590,592\n",
      "          Linear-134             [-1, 197, 768]         590,592\n",
      "          Linear-135             [-1, 197, 768]         590,592\n",
      "         Dropout-136          [-1, 12, 197, 64]               0\n",
      "          Linear-137             [-1, 197, 768]         590,592\n",
      "         Dropout-138             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-139             [-1, 197, 768]               0\n",
      "       LayerNorm-140             [-1, 197, 768]           1,536\n",
      "          Linear-141            [-1, 197, 3072]       2,362,368\n",
      "            GELU-142            [-1, 197, 3072]               0\n",
      "         Dropout-143            [-1, 197, 3072]               0\n",
      "          Linear-144             [-1, 197, 768]       2,360,064\n",
      "         Dropout-145             [-1, 197, 768]               0\n",
      "             MLP-146             [-1, 197, 768]               0\n",
      "TransformerEncoder-147             [-1, 197, 768]               0\n",
      "       LayerNorm-148             [-1, 197, 768]           1,536\n",
      "          Linear-149             [-1, 197, 768]         590,592\n",
      "          Linear-150             [-1, 197, 768]         590,592\n",
      "          Linear-151             [-1, 197, 768]         590,592\n",
      "         Dropout-152          [-1, 12, 197, 64]               0\n",
      "          Linear-153             [-1, 197, 768]         590,592\n",
      "         Dropout-154             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-155             [-1, 197, 768]               0\n",
      "       LayerNorm-156             [-1, 197, 768]           1,536\n",
      "          Linear-157            [-1, 197, 3072]       2,362,368\n",
      "            GELU-158            [-1, 197, 3072]               0\n",
      "         Dropout-159            [-1, 197, 3072]               0\n",
      "          Linear-160             [-1, 197, 768]       2,360,064\n",
      "         Dropout-161             [-1, 197, 768]               0\n",
      "             MLP-162             [-1, 197, 768]               0\n",
      "TransformerEncoder-163             [-1, 197, 768]               0\n",
      "       LayerNorm-164             [-1, 197, 768]           1,536\n",
      "          Linear-165             [-1, 197, 768]         590,592\n",
      "          Linear-166             [-1, 197, 768]         590,592\n",
      "          Linear-167             [-1, 197, 768]         590,592\n",
      "         Dropout-168          [-1, 12, 197, 64]               0\n",
      "          Linear-169             [-1, 197, 768]         590,592\n",
      "         Dropout-170             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-171             [-1, 197, 768]               0\n",
      "       LayerNorm-172             [-1, 197, 768]           1,536\n",
      "          Linear-173            [-1, 197, 3072]       2,362,368\n",
      "            GELU-174            [-1, 197, 3072]               0\n",
      "         Dropout-175            [-1, 197, 3072]               0\n",
      "          Linear-176             [-1, 197, 768]       2,360,064\n",
      "         Dropout-177             [-1, 197, 768]               0\n",
      "             MLP-178             [-1, 197, 768]               0\n",
      "TransformerEncoder-179             [-1, 197, 768]               0\n",
      "       LayerNorm-180             [-1, 197, 768]           1,536\n",
      "          Linear-181             [-1, 197, 768]         590,592\n",
      "          Linear-182             [-1, 197, 768]         590,592\n",
      "          Linear-183             [-1, 197, 768]         590,592\n",
      "         Dropout-184          [-1, 12, 197, 64]               0\n",
      "          Linear-185             [-1, 197, 768]         590,592\n",
      "         Dropout-186             [-1, 197, 768]               0\n",
      "MultiHeadSelfAttention-187             [-1, 197, 768]               0\n",
      "       LayerNorm-188             [-1, 197, 768]           1,536\n",
      "          Linear-189            [-1, 197, 3072]       2,362,368\n",
      "            GELU-190            [-1, 197, 3072]               0\n",
      "         Dropout-191            [-1, 197, 3072]               0\n",
      "          Linear-192             [-1, 197, 768]       2,360,064\n",
      "         Dropout-193             [-1, 197, 768]               0\n",
      "             MLP-194             [-1, 197, 768]               0\n",
      "TransformerEncoder-195             [-1, 197, 768]               0\n",
      "          Linear-196                   [-1, 10]           7,690\n",
      "================================================================\n",
      "Total params: 86,243,338\n",
      "Trainable params: 86,243,338\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 349.74\n",
      "Params size (MB): 328.99\n",
      "Estimated Total Size (MB): 679.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_batches = 10\n",
    "image_size, in_channels = 224, 3\n",
    "patch_size = 16\n",
    "embed_dim = 768\n",
    "num_layers = 12\n",
    "mlp_dim = 3072\n",
    "num_heads = 12\n",
    "drop_p = 0.5\n",
    "num_classes = 10\n",
    "\n",
    "dummy_x = torch.randn((num_batches, in_channels, image_size, image_size))\n",
    "vit_model = ViT(image_size, in_channels, patch_size, num_layers, embed_dim, mlp_dim, num_heads, drop_p, num_classes)\n",
    "out = vit_model(dummy_x)\n",
    "print(f\"out: {out.shape}\")\n",
    "torchsummary.summary(vit_model, input_size=(in_channels, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.980373 to fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'images/vit_model.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph = make_dot(out, params=dict(vit_model.named_parameters()))\n",
    "model_graph.format = 'png'\n",
    "model_graph.directory = 'images'  \n",
    "model_graph.render('vit_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
